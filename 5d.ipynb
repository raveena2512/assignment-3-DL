{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5d.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd-5HF-vd0c3"
      },
      "outputs": [],
      "source": [
        "from matplotlib.font_manager import FontProperties\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib as mpl\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "mpl.rcParams['font.sans-serif'] = [\"Arial Unicode MS\"]\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence,orig,hind,deco):\n",
        "    \n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    plott = ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "    hindi_font = FontProperties(fname = 'Regular.ttf')\n",
        "    \n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontproperties=hindi_font, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    \n",
        "    title = f\"Original word in english: {orig}\\nOriginal word in hindi: {hind}\\nDecoded word in hindi: {deco}\"\n",
        "    \n",
        "    fontdict = {'fontsize': 18}\n",
        "    plt.title(title,fontproperties=hindi_font, fontsize=14,y=-.3)\n",
        "    \n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"7%\", pad=0.1)\n",
        "    plt.colorbar(plott,cax=cax)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'res/{orig}.png', bbox_inches = 'tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "iG8NiwCYbzcg"
      },
      "outputs": [],
      "source": [
        "eve = df.values\n",
        "\n",
        "for _ in range(9):\n",
        "    sp = np.random.choice(eve.shape[0])\n",
        "\n",
        "    decoded_sentence_list = [x for x in eve[sp][2].strip()] + ['<end>']\n",
        "    input_sentence_list = [x for x in eve[sp][0].strip()] + ['<end>']\n",
        "\n",
        "    attention_plot = att_wts[sp][0][:len(input_sentence_list),:len(decoded_sentence_list)].T\n",
        "\n",
        "    print(\"Original word in english:\", eve[sp][0])\n",
        "    print(\"Original word in hindi:\", eve[sp][1])\n",
        "    print(\"Decoded word in hindi:\", eve[sp][2])\n",
        "\n",
        "    plot_attention(attention_plot, input_sentence_list, decoded_sentence_list,eve[sp][0],eve[sp][1],eve[sp][2])\n"
      ]
    }
  ]
}